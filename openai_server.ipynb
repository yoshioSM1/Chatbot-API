{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Class\n",
    "\n",
    "Lo primero que hay que hacer, es instalar el paque de openai \n",
    "\n",
    "```bash\n",
    "pip install openai\n",
    "```\n",
    "\n",
    "y tener un API Key \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI ## pip install openai\n",
    "from dotenv import load_dotenv ## pip install python-dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "openai_client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\") ## https://api.openai.com/v1 -> Custom server\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Large Language Models (LLMs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Language Models (llms)\n",
    "\n",
    "* GPT-4 (OpenAI)\n",
    "* DeepSeek R1 (DeepSeek)\n",
    "* Claude 3.5 Sonnet (Anthropic)\n",
    "\n",
    "\n",
    "# Format\n",
    "\n",
    "```json\n",
    "messages: List[Dict] = {\n",
    "    \"role\": \"user\" | \"assistant\" | \"system\",\n",
    "    \"content\": \"Hello, how are you?\"\n",
    "}\n",
    "```\n",
    "model: \n",
    "temperature:\n",
    "\n",
    "max_tokens:\n",
    "\n",
    "top_p\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that can answer questions and help with tasks.\" ## Prompt Engineering\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you give me a recipe\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.5, # Que tan creativo es el modelo\n",
    "    max_tokens=600, ## Cantidad de palabras/silabas que se van a generar por el model \n",
    "    top_p=1, ## El modelo va a tener en cuenta el 100% de las palabras/silabas que se le dan\n",
    "    n=1, ## Cantidad de respuestas que se van a generar\n",
    "    user=\"yoshio.soto@softtek.com\" # Para poder hacer un seguimiento de las respuestas\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Of course! What type of recipe are you looking for? It could be anything from a main dish, dessert, appetizer, or  \n",
       "even a drink. Let me know your preferences or any specific ingredients you have in mind!                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Of course! What type of recipe are you looking for? It could be anything from a main dish, dessert, appetizer, or  \n",
       "even a drink. Let me know your preferences or any specific ingredients you have in mind!                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.markdown import Markdown\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "console.print(Markdown(response.choices[0].message.content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! What type of recipe are you looking for? It could be anything from appetizers to desserts, vegetarian to meat-based. Let me know your preferences!"
     ]
    }
   ],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that can answer questions and help with tasks.\" ## Prompt Engineering\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you give me a recipe\"\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    temperature=0.5, # Que tan creativo es el modelo\n",
    "    max_tokens=1200, ## Cantidad de palabras/silabas que se van a generar por el model \n",
    "    top_p=1, ## El modelo va a tener en cuenta el 100% de las palabras/silabas que se le dan\n",
    "    n=3, ## Cantidad de respuestas que se van a generar\n",
    "    user=\"yoshio.soto@softtek.com\" # Para poder hacer un seguimiento de las respuestas\n",
    ")\n",
    "\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llms': ['gpt-4o',\n",
       "  'gpt-4o-mini',\n",
       "  'o1',\n",
       "  'o1-mini',\n",
       "  'o3-mini',\n",
       "  'claude-3-5-sonnet',\n",
       "  'claude-3-7-sonnet',\n",
       "  'claude-3-5-haiku',\n",
       "  'deepseek-r1',\n",
       "  'llama-3.1-70B',\n",
       "  'llama-3.1-405B'],\n",
       " 'embeddings': ['text-ada-002',\n",
       "  'text-embedding-3-small',\n",
       "  'text-embedding-3-large',\n",
       "  'all-mpnet-base-v2',\n",
       "  'multi-qa-MiniLM-L6-cos-v1'],\n",
       " 'images': ['dall-e-3']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\n",
    "    f\"{os.getenv('OPENAI_BASE_URL')}/models\"\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'llms': ['gpt-4o', # Para respuestas mas largas/complejas\n",
    "  'gpt-4o-mini', # Pequeño para respuesas cortas/rapidas\n",
    "  'o1', # Capacidad de razonamiento mas grandes \n",
    "  'o1-mini', # Capacidad de razonamiento mas pequeña\n",
    "  'o3-mini', # Modelo de razonamiento mas rapido y mas economico \n",
    "  'claude-3-5-sonnet',\n",
    "  'claude-3-7-sonnet',\n",
    "  'claude-3-5-haiku',\n",
    "  'deepseek-r1',\n",
    "  'llama-3.1-70B',\n",
    "  'llama-3.1-405B'],\n",
    " 'embeddings': ['text-ada-002',\n",
    "  'text-embedding-3-small',\n",
    "  'text-embedding-3-large',\n",
    "  'all-mpnet-base-v2',\n",
    "  'multi-qa-MiniLM-L6-cos-v1'],\n",
    " 'images': ['dall-e-3']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that can answer questions and help with tasks.\" ## Prompt Engineering\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you give me a list of the top 100 companies in the world? and their revenue of 2023\"\n",
    "        }\n",
    "    ]\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=messages,\n",
    "    top_p=1, ## El modelo va a tener en cuenta el 100% de las palabras/silabas que se le dan\n",
    "    n=3, ## Cantidad de respuestas que se van a generar\n",
    "    user=\"jorge.garcias@softtek.com\" # Para poder hacer un seguimiento de las respuestas\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is some important context before the list:\n",
      "\n",
      "• Several respected sources (such as Fortune and Forbes) publish yearly rankings of “the world’s largest companies” based on annual revenue. One of the most commonly referenced is the Fortune Global 500 list. (Other listings—by market capitalization or assets, for example—use different criteria.)  \n",
      "• Revenue numbers can vary depending on currency‐conversion methods, reporting period differences, and when the data was collected, so figures are usually “approximate” (often rounded to the nearest billion US dollars).  \n",
      "• Because companies report on different calendars or fiscal years, and updated numbers sometimes lag behind the calendar year, please note that even a “2023” list is based on the best available recent information (often data from the 2022 fiscal year that were compiled into a 2023 ranking).\n",
      "\n",
      "With that in mind, below is an illustrative (approximate) list of 100 of the world’s largest companies by annual revenue as reported in or around 2023. (This list is based on publicly available data and past Fortune Global 500 information; details may differ slightly from one source to another.) If you need absolute precision it’s best to consult the latest official report (for example at fortune.com/global500).\n",
      "\n",
      "──────────────────────────────\n",
      "Approximate Top 100 Companies by Revenue (2023)\n",
      "(All revenue figures are given in billions of U.S. dollars, rounded to one decimal place)\n",
      "\n",
      "1. Walmart (USA) – 572.8  \n",
      "2. Saudi Aramco (Saudi Arabia) – ~570.0  \n",
      "3. Amazon.com (USA) – ~470.0  \n",
      "4. State Grid (China) – ~460.6  \n",
      "5. China National Petroleum (China) – ~411.7  \n",
      "6. Sinopec Group (China) – ~407.0  \n",
      "7. Apple (USA) – ~384.0  \n",
      "8. UnitedHealth Group (USA) – ~324.2  \n",
      "9. CVS Health (USA) – ~322.5  \n",
      "10. Berkshire Hathaway (USA) – ~276.1  \n",
      "\n",
      "11. Toyota Motor (Japan) – ~275.4  \n",
      "12. Volkswagen (Germany) – ~275.2  \n",
      "13. Royal Dutch Shell (UK/Netherlands) – ~272.3  \n",
      "14. ExxonMobil (USA) – ~236.5  \n",
      "15. McKesson (USA) – ~231.1  \n",
      "16. Glencore (Switzerland) – ~215.1  \n",
      "17. Daimler (Germany) – ~203.4  \n",
      "18. AT&T (USA) – ~192.6  \n",
      "19. Ford Motor (USA) – ~158.0  \n",
      "20. General Motors (USA) – ~156.7  \n",
      "\n",
      "21. AmerisourceBergen (USA) – ~156.5  \n",
      "22. Chevron (USA) – ~155.3  \n",
      "23. Cardinal Health (USA) – ~152.9  \n",
      "24. Costco Wholesale (USA) – ~152.7  \n",
      "25. Ping An Insurance Group (China) – ~143.4  \n",
      "26. Honda Motor (Japan) – ~137.3  \n",
      "27. Industrial & Commercial Bank of China (China) – ~136.7  \n",
      "28. Agricultural Bank of China (China) – ~135.9  \n",
      "29. Japan Post Holdings (Japan) – ~133.2  \n",
      "30. Mitsubishi Corporation (Japan) – ~130.4  \n",
      "\n",
      "31. BMW Group (Germany) – ~129.5  \n",
      "32. Bank of China (China) – ~128.7  \n",
      "33. China Construction Bank (China) – ~127.8  \n",
      "34. TotalEnergies (France) – ~127.5  \n",
      "35. Allianz (Germany) – ~126.3  \n",
      "36. JPMorgan Chase (USA) – ~125.2  \n",
      "37. BP (UK) – ~124.8  \n",
      "38. China Mobile (China) – ~123.7  \n",
      "39. China State Construction Engineering (China) – ~122.9  \n",
      "40. Hyundai Motor (South Korea) – ~121.5  \n",
      "\n",
      "41. AIA Group (Hong Kong) – ~120.3  \n",
      "42. Enel (Italy) – ~119.1  \n",
      "43. Siemens (Germany) – ~118.7  \n",
      "44. Nissan Motor (Japan) – ~117.8  \n",
      "45. Kroger (USA) – ~116.2  \n",
      "46. Dow Chemical (USA) – ~115.9  \n",
      "47. Reliance Industries (India) – ~115.4  \n",
      "48. China Life Insurance (China) – ~114.8  \n",
      "49. NTT (Japan) – ~113.7  \n",
      "50. Lukoil (Russia) – ~112.9  \n",
      "\n",
      "51. Banco Santander (Spain) – ~112.0  \n",
      "52. Wells Fargo (USA) – ~111.5  \n",
      "53. Rosneft (Russia) – ~110.7  \n",
      "54. JD.com (China) – ~110.0  \n",
      "55. Aegon (Netherlands) – ~109.5  \n",
      "56. Prudential (UK) – ~109.0  \n",
      "57. Marathon Petroleum (USA) – ~108.3  \n",
      "58. China Merchants Bank (China) – ~108.0  \n",
      "59. State Farm (USA) – ~107.5  \n",
      "60. SoftBank (Japan) – ~107.0  \n",
      "\n",
      "61. China CITIC Bank (China) – ~106.6  \n",
      "62. MetLife (USA) – ~106.2  \n",
      "63. Assicurazioni Generali (Italy) – ~105.8  \n",
      "64. ING Group (Netherlands) – ~105.3  \n",
      "65. China Minsheng Banking (China) – ~105.0  \n",
      "66. MetLife (USA) – (if reported separately, otherwise see above)  \n",
      "67. AXA (France) – ~104.5  \n",
      "68. Rabobank (Netherlands) – ~104.0  \n",
      "69. Societe Generale (France) – ~103.5  \n",
      "70. UniCredit (Italy) – ~103.0  \n",
      "\n",
      "71. Deutsche Telekom (Germany) – ~102.5  \n",
      "72. E.ON (Germany) – ~102.0  \n",
      "73. Saint-Gobain (France) – ~101.5  \n",
      "74. Hitachi (Japan) – ~101.0  \n",
      "75. Mitsui (Japan) – ~100.5  \n",
      "76. AstraZeneca (UK) – ~100.0  \n",
      "77. Verizon (USA) – ~99.5  \n",
      "78. Credit Suisse (Switzerland) – ~99.0  \n",
      "79. BNP Paribas (France) – ~98.5  \n",
      "80. Barclays (UK) – ~98.0  \n",
      "\n",
      "81. The Home Depot (USA) – ~97.5  \n",
      "82. Oracle (USA) – ~97.0  \n",
      "83. FedEx (USA) – ~96.5  \n",
      "84. Rabobank (Netherlands) – (if separate, otherwise see above)  \n",
      "85. M&T Bank (USA) – ~96.0  \n",
      "86. Lockheed Martin (USA) – ~95.5  \n",
      "87. Raytheon Technologies (USA) – ~95.0  \n",
      "88. Prudential (USA) – (if distinct from U.K. operations) ~94.5  \n",
      "89. Aflac (USA) – ~94.0  \n",
      "90. Chubb (USA) – ~93.5  \n",
      "\n",
      "91. Tesco (UK) – ~93.0  \n",
      "92. GlaxoSmithKline (UK) – ~92.5  \n",
      "93. Vodafone (UK) – ~92.0  \n",
      "94. Mitsubishi UFJ Financial (Japan) – ~91.5  \n",
      "95. Sumitomo Mitsui Banking (Japan) – ~91.0  \n",
      "96. Sberbank (Russia) – ~90.5  \n",
      "97. Marriott International (USA) – ~90.0  \n",
      "98. General Electric (USA) – ~89.5  \n",
      "99. Verizon (USA) – (if reported separately, otherwise see above) ~89.0  \n",
      "100. Dell Technologies (USA) – ~88.5  \n",
      "\n",
      "──────────────────────────────\n",
      "Important Notes about the Above List:\n",
      "• These rankings and numbers are meant to serve as an illustrative approximation based on a synthesis of publicly available data and past editions of the Global 500.  \n",
      "• (Some large financial institutions and insurers report revenues that are structured differently from industrial companies; rounding and ordering can therefore vary by source.)  \n",
      "• In several cases a company might be reported more than once by related operating units; the list above represents one commonly cited “global revenue” figure for each.\n",
      "\n",
      "For the most authoritative and up‐to‐date information, please refer to the latest Fortune Global 500 publication or the companies’ own annual reports.\n",
      "\n",
      "I hope this helps! Would you like further details or clarifications on any part of the list?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response.choices[0].message)\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"And what are some companies that are not in the list that are worth investing in?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not a financial advisor, so please consider the following as informational examples rather than personalized recommendations. That said, many investors look beyond the largest companies by revenue and instead focus on growth potential, innovation, market leadership, and strong fundamentals. Here are some examples from different sectors that have caught the attention of investors (note that many of these companies are well known for their market cap, technology leadership, or growth profiles even if they don't make a top‐100 revenue ranking):\n",
      "\n",
      "1. Technology & Software  \n",
      " • Microsoft – A technology giant with a wide range of products and a strong cloud business.  \n",
      " • Alphabet (Google) – Dominant in search and digital advertising, with significant investments in AI and cloud computing.  \n",
      " • Nvidia – Known for its graphics processing units (GPUs) and leading position in AI and data center technologies.  \n",
      " • Adobe – A leader in creative and digital marketing software, continuing to grow through its subscription-based model.  \n",
      " • Salesforce – A major player in cloud-based customer relationship management (CRM) solutions.\n",
      "\n",
      "2. Consumer & E-Commerce  \n",
      " • Tesla – Although its revenue might be lower than some traditional industrial giants, Tesla is hailed as a major innovator in electric vehicles and energy solutions.  \n",
      " • Shopify – An e-commerce platform that has empowered many small and medium-sized businesses online.  \n",
      " • Amazon Web Services (AWS) – While Amazon’s core retail business is huge and appears on lists based on revenue, its cloud segment often distinguishes itself as a high-growth tech leader on its own merits.\n",
      "\n",
      "3. Emerging & Innovative Sectors  \n",
      " • ASML Technologies – A crucial supplier in the semiconductor manufacturing industry with a near-monopoly in advanced lithography systems.  \n",
      " • Moderna (or BioNTech) – Key players in biotech that sparked investor interest following their pivotal roles in vaccine development and have platforms with further potential in infectious diseases and beyond.\n",
      "\n",
      "4. Specialized or Niche Markets  \n",
      " • Square (now Block, Inc.) – Focused on digital payments and financial technology innovations, tapping into the broader fintech revolution.  \n",
      " • Zoom Video Communications – Emerged as a staple in virtual communications, with continued potential as remote and hybrid work models evolve.\n",
      "\n",
      "Each of these companies has different growth drivers and risk profiles. Before making any investment decisions, consider doing thorough research (for example, reviewing financial statements, competitive positioning, market trends, etc.) and consulting with a qualified financial advisor to align choices with your personal financial goals and risk tolerance.\n",
      "\n",
      "Remember, diversification is key, and what’s attractive for one investor might not fit another’s portfolio strategy. Always do your due diligence before investing.\n"
     ]
    }
   ],
   "source": [
    "last_response = openai_client.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=messages,\n",
    "    top_p=1, ## El modelo va a tener en cuenta el 100% de las palabras/silabas que se le dan\n",
    "    n=3, ## Cantidad de respuestas que se van a generar\n",
    "    user=\"jorge.garcias@softtek.com\" # Para poder hacer un seguimiento de las respuestas\n",
    ")\n",
    "print(last_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'detail': \"Error generating image: 'NoneType' object has no attribute 'prompt_tokens'\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 2\u001b[0m new_image \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdall-e-3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA beautiful landscape with a river and mountains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1024x1024\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_image\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m     10\u001b[0m Image\u001b[38;5;241m.\u001b[39mopen(requests\u001b[38;5;241m.\u001b[39mget(new_image\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39murl, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mraw)\n",
      "File \u001b[0;32m~/Documents/Coding/OnboardingInnovation/.venv/lib/python3.10/site-packages/openai/resources/images.py:264\u001b[0m, in \u001b[0;36mImages.generate\u001b[0;34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImagesResponse:\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    Creates an image given a prompt.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/images/generations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstyle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageGenerateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImagesResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/OnboardingInnovation/.venv/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/Coding/OnboardingInnovation/.venv/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/OnboardingInnovation/.venv/lib/python3.10/site-packages/openai/_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Documents/Coding/OnboardingInnovation/.venv/lib/python3.10/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/OnboardingInnovation/.venv/lib/python3.10/site-packages/openai/_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Documents/Coding/OnboardingInnovation/.venv/lib/python3.10/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/OnboardingInnovation/.venv/lib/python3.10/site-packages/openai/_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1022\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1026\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1032\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 500 - {'detail': \"Error generating image: 'NoneType' object has no attribute 'prompt_tokens'\"}"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "new_image = openai_client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"A beautiful landscape with a river and mountains\",\n",
    "    n=1,\n",
    "    size=\"1024x1024\"\n",
    ")\n",
    "print(new_image.data[0].url)\n",
    "\n",
    "Image.open(requests.get(new_image.data[0].url, stream=True).raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a technical diagram of an AWS (Amazon Web Services) Cloud architecture workflow. \n",
      "\n",
      "The main subject of the image is an AWS Step Functions workflow that illustrates how a user can interact with various AWS services to set up and configure AWS resources. The diagram is divided into several components:\n",
      "\n",
      "1. On the left side, it shows a user who can use either \"awscurl\" or a Python script to interact with an API Gateway\n",
      "2. The central part displays the AWS Step Functions workflow (highlighted in pink) with numbered steps:\n",
      "   - Run Landing Zone Accelerator on AWS (3)\n",
      "   - Optional: Sync account (4)\n",
      "   - Create additional account resources (5)\n",
      "   - Optional: Add permission set (6)\n",
      "   - Run QA and validation tests (7)\n",
      "   - Release account (8)\n",
      "\n",
      "3. The bottom portion shows various AWS services involved:\n",
      "   - Landing Zone Accelerator on AWS with account-config.yaml and CodePipeline\n",
      "   - Entra ID\n",
      "   - AWS Organizations and IAM\n",
      "   - IAM Identity Center\n",
      "   - Amazon SNS\n",
      "\n",
      "This appears to be a technical architecture diagram for automating the deployment and configuration of AWS accounts, likely as part of a multi-account AWS infrastructure setup using AWS Landing Zone Accelerator."
     ]
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "\n",
    "\n",
    "console = Console()\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"claude-3-7-sonnet\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": \n",
    "            [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What do you see in this image? And what do you think is the main subject of the image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"https://docs.aws.amazon.com/images/prescriptive-guidance/latest/patterns/images/pattern-img/d31abfaa-6854-4923-b896-3b817de9f4d9/images/dfd6503d-a4ed-43df-82d4-082f8153d473.png\"\n",
    "                }\n",
    "            }\n",
    "        ]},\n",
    "    ],\n",
    "    stream=True,\n",
    "    user=\"jorge.garcias@softtek.com\",\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
